{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from stable_baselines import BDQ, DQN, DDPG\n",
    "from stable_baselines.bdq.policies import ActionBranching\n",
    "from stable_baselines.ddpg.policies import MlpPolicy as DDPGMlp\n",
    "from stable_baselines.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec\n",
    "\n",
    "from stable_baselines.deepq.policies import MlpPolicy\n",
    "import gym\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Humanoid-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN(MlpPolicy, disc_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(env.reset())[None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Reacher-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barisyazici/anaconda3/envs/sb_action/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Pendulum-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "param_noise = None\n",
    "action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(DDPGMlp, env, verbose=1, param_noise=param_noise, action_noise=action_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/common/tf_util.py:58: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/common/tf_util.py:67: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/bdq/build_graph.py:620: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/bdq/build_graph.py:621: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/bdq/build_graph.py:518: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/bdq/policies.py:174: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /Users/barisyazici/anaconda3/envs/sb_action/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "actor q_function [<tf.Tensor 'bdq/model/add:0' shape=(?, 33) dtype=float32>]\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/bdq/build_graph.py:539: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/bdq/build_graph.py:638: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/bdq/build_graph.py:638: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/bdq/build_graph.py:638: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "q_function to optimize [<tf.Tensor 'bdq/step_model/model/add:0' shape=(?, 33) dtype=float32>]\n",
      "qfunction parameters [<tf.Variable 'bdq/model/common_net/fully_connected/weights:0' shape=(3, 512) dtype=float32_ref>, <tf.Variable 'bdq/model/common_net/fully_connected/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bdq/model/common_net/fully_connected_1/weights:0' shape=(512, 256) dtype=float32_ref>, <tf.Variable 'bdq/model/common_net/fully_connected_1/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'bdq/model/action_value/fully_connected/weights:0' shape=(256, 128) dtype=float32_ref>, <tf.Variable 'bdq/model/action_value/fully_connected/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'bdq/model/action_value/fully_connected_1/weights:0' shape=(128, 33) dtype=float32_ref>, <tf.Variable 'bdq/model/action_value/fully_connected_1/biases:0' shape=(33,) dtype=float32_ref>, <tf.Variable 'bdq/model/state_value/fully_connected/weights:0' shape=(256, 128) dtype=float32_ref>, <tf.Variable 'bdq/model/state_value/fully_connected/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'bdq/model/state_value/fully_connected_1/weights:0' shape=(128, 1) dtype=float32_ref>, <tf.Variable 'bdq/model/state_value/fully_connected_1/biases:0' shape=(1,) dtype=float32_ref>]\n",
      "target q_func [<tf.Tensor 'bdq/target_q_func/model/add:0' shape=(?, 33) dtype=float32>]\n",
      "target q_func vars [<tf.Variable 'bdq/target_q_func/model/common_net/fully_connected/weights:0' shape=(3, 512) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/common_net/fully_connected/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/common_net/fully_connected_1/weights:0' shape=(512, 256) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/common_net/fully_connected_1/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/action_value/fully_connected/weights:0' shape=(256, 128) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/action_value/fully_connected/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/action_value/fully_connected_1/weights:0' shape=(128, 33) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/action_value/fully_connected_1/biases:0' shape=(33,) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/state_value/fully_connected/weights:0' shape=(256, 128) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/state_value/fully_connected/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/state_value/fully_connected_1/weights:0' shape=(128, 1) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/state_value/fully_connected_1/biases:0' shape=(1,) dtype=float32_ref>]\n",
      "double q_func [<tf.Tensor 'bdq/q_func/model/add:0' shape=(?, 33) dtype=float32>]\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/bdq/build_graph.py:713: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/barisyazici/anaconda3/envs/sb_action/lib/python3.6/site-packages/tensorflow_core/python/ops/clip_ops.py:172: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/bdq/build_graph.py:761: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/bdq/build_graph.py:768: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/bdq/build_graph.py:791: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "trainable vars [<tf.Variable 'bdq/eps:0' shape=() dtype=float32_ref>, <tf.Variable 'bdq/model/common_net/fully_connected/weights:0' shape=(3, 512) dtype=float32_ref>, <tf.Variable 'bdq/model/common_net/fully_connected/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bdq/model/common_net/fully_connected_1/weights:0' shape=(512, 256) dtype=float32_ref>, <tf.Variable 'bdq/model/common_net/fully_connected_1/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'bdq/model/action_value/fully_connected/weights:0' shape=(256, 128) dtype=float32_ref>, <tf.Variable 'bdq/model/action_value/fully_connected/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'bdq/model/action_value/fully_connected_1/weights:0' shape=(128, 33) dtype=float32_ref>, <tf.Variable 'bdq/model/action_value/fully_connected_1/biases:0' shape=(33,) dtype=float32_ref>, <tf.Variable 'bdq/model/state_value/fully_connected/weights:0' shape=(256, 128) dtype=float32_ref>, <tf.Variable 'bdq/model/state_value/fully_connected/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'bdq/model/state_value/fully_connected_1/weights:0' shape=(128, 1) dtype=float32_ref>, <tf.Variable 'bdq/model/state_value/fully_connected_1/biases:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/common_net/fully_connected/weights:0' shape=(3, 512) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/common_net/fully_connected/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/common_net/fully_connected_1/weights:0' shape=(512, 256) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/common_net/fully_connected_1/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/action_value/fully_connected/weights:0' shape=(256, 128) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/action_value/fully_connected/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/action_value/fully_connected_1/weights:0' shape=(128, 33) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/action_value/fully_connected_1/biases:0' shape=(33,) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/state_value/fully_connected/weights:0' shape=(256, 128) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/state_value/fully_connected/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/state_value/fully_connected_1/weights:0' shape=(128, 1) dtype=float32_ref>, <tf.Variable 'bdq/target_q_func/model/state_value/fully_connected_1/biases:0' shape=(1,) dtype=float32_ref>]\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/common/tf_util.py:108: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/common/tf_util.py:109: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = BDQ(ActionBranching, env, verbose=2, tensorboard_log='tensorboard_logs/Pendulum', full_tensorboard_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_parameter_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.step_model.q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.policy.processed_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/common/base_class.py:1082: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/common/tf_util.py:188: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/a2c/utils.py:581: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "ep number 1\n",
      "ep number 2\n",
      "ep number 3\n",
      "ep number 4\n",
      "ep number 5\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/bdq/bdq.py:315: The name tf.RunOptions is deprecated. Please use tf.compat.v1.RunOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/barisyazici/Desktop/ActionBranchingQ-Learning/algorithms/bdq_sb/stable_baselines/bdq/bdq.py:316: The name tf.RunMetadata is deprecated. Please use tf.compat.v1.RunMetadata instead.\n",
      "\n",
      "ep number 6\n",
      "ep number 7\n",
      "ep number 8\n",
      "ep number 9\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 83        |\n",
      "| episodes                | 10        |\n",
      "| mean 100 episode reward | -1.16e+03 |\n",
      "| steps                   | 1799      |\n",
      "---------------------------------------\n",
      "ep number 10\n",
      "ep number 11\n",
      "ep number 12\n",
      "ep number 13\n",
      "ep number 14\n",
      "ep number 15\n",
      "ep number 16\n",
      "ep number 17\n",
      "ep number 18\n",
      "ep number 19\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 65        |\n",
      "| episodes                | 20        |\n",
      "| mean 100 episode reward | -1.29e+03 |\n",
      "| steps                   | 3799      |\n",
      "---------------------------------------\n",
      "ep number 20\n",
      "ep number 21\n",
      "ep number 22\n",
      "ep number 23\n",
      "ep number 24\n",
      "ep number 25\n",
      "ep number 26\n",
      "ep number 27\n",
      "ep number 28\n",
      "ep number 29\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 47       |\n",
      "| episodes                | 30       |\n",
      "| mean 100 episode reward | -1.2e+03 |\n",
      "| steps                   | 5799     |\n",
      "--------------------------------------\n",
      "ep number 30\n",
      "ep number 31\n",
      "ep number 32\n",
      "ep number 33\n",
      "ep number 34\n",
      "ep number 35\n",
      "ep number 36\n",
      "ep number 37\n",
      "ep number 38\n",
      "ep number 39\n",
      "---------------------------------------\n",
      "| % time spent exploring  | 29        |\n",
      "| episodes                | 40        |\n",
      "| mean 100 episode reward | -1.07e+03 |\n",
      "| steps                   | 7799      |\n",
      "---------------------------------------\n",
      "ep number 40\n",
      "ep number 41\n",
      "ep number 42\n",
      "ep number 43\n",
      "ep number 44\n",
      "ep number 45\n",
      "ep number 46\n",
      "ep number 47\n",
      "ep number 48\n",
      "ep number 49\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 11       |\n",
      "| episodes                | 50       |\n",
      "| mean 100 episode reward | -910     |\n",
      "| steps                   | 9799     |\n",
      "--------------------------------------\n",
      "ep number 50\n",
      "ep number 51\n",
      "ep number 52\n",
      "ep number 53\n",
      "ep number 54\n",
      "ep number 55\n",
      "ep number 56\n",
      "ep number 57\n",
      "ep number 58\n",
      "ep number 59\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 9        |\n",
      "| episodes                | 60       |\n",
      "| mean 100 episode reward | -777     |\n",
      "| steps                   | 11799    |\n",
      "--------------------------------------\n",
      "ep number 60\n",
      "ep number 61\n",
      "ep number 62\n",
      "ep number 63\n",
      "ep number 64\n",
      "ep number 65\n",
      "ep number 66\n",
      "ep number 67\n",
      "ep number 68\n",
      "ep number 69\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 9        |\n",
      "| episodes                | 70       |\n",
      "| mean 100 episode reward | -687     |\n",
      "| steps                   | 13799    |\n",
      "--------------------------------------\n",
      "ep number 70\n",
      "ep number 71\n",
      "ep number 72\n",
      "ep number 73\n",
      "ep number 74\n",
      "ep number 75\n",
      "ep number 76\n",
      "ep number 77\n",
      "ep number 78\n",
      "ep number 79\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 9        |\n",
      "| episodes                | 80       |\n",
      "| mean 100 episode reward | -629     |\n",
      "| steps                   | 15799    |\n",
      "--------------------------------------\n",
      "ep number 80\n",
      "ep number 81\n",
      "ep number 82\n",
      "ep number 83\n",
      "ep number 84\n",
      "ep number 85\n",
      "ep number 86\n",
      "ep number 87\n",
      "ep number 88\n",
      "ep number 89\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 9        |\n",
      "| episodes                | 90       |\n",
      "| mean 100 episode reward | -572     |\n",
      "| steps                   | 17799    |\n",
      "--------------------------------------\n",
      "ep number 90\n",
      "ep number 91\n",
      "ep number 92\n",
      "ep number 93\n",
      "ep number 94\n",
      "ep number 95\n",
      "ep number 96\n",
      "ep number 97\n",
      "ep number 98\n",
      "ep number 99\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 9        |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | -530     |\n",
      "| steps                   | 19799    |\n",
      "--------------------------------------\n",
      "ep number 100\n",
      "ep number 101\n",
      "ep number 102\n",
      "ep number 103\n",
      "ep number 104\n",
      "ep number 105\n",
      "ep number 106\n",
      "ep number 107\n",
      "ep number 108\n",
      "ep number 109\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 8        |\n",
      "| episodes                | 110      |\n",
      "| mean 100 episode reward | -446     |\n",
      "| steps                   | 21799    |\n",
      "--------------------------------------\n",
      "ep number 110\n",
      "ep number 111\n",
      "ep number 112\n",
      "ep number 113\n",
      "ep number 114\n",
      "ep number 115\n",
      "ep number 116\n",
      "ep number 117\n",
      "ep number 118\n",
      "ep number 119\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 8        |\n",
      "| episodes                | 120      |\n",
      "| mean 100 episode reward | -328     |\n",
      "| steps                   | 23799    |\n",
      "--------------------------------------\n",
      "ep number 120\n",
      "ep number 121\n",
      "ep number 122\n",
      "ep number 123\n",
      "ep number 124\n",
      "ep number 125\n",
      "ep number 126\n",
      "ep number 127\n",
      "ep number 128\n",
      "ep number 129\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 8        |\n",
      "| episodes                | 130      |\n",
      "| mean 100 episode reward | -247     |\n",
      "| steps                   | 25799    |\n",
      "--------------------------------------\n",
      "ep number 130\n",
      "ep number 131\n",
      "ep number 132\n",
      "ep number 133\n",
      "ep number 134\n",
      "ep number 135\n",
      "ep number 136\n",
      "ep number 137\n",
      "ep number 138\n",
      "ep number 139\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 8        |\n",
      "| episodes                | 140      |\n",
      "| mean 100 episode reward | -207     |\n",
      "| steps                   | 27799    |\n",
      "--------------------------------------\n",
      "ep number 140\n",
      "ep number 141\n",
      "ep number 142\n",
      "ep number 143\n",
      "ep number 144\n",
      "ep number 145\n",
      "ep number 146\n",
      "ep number 147\n",
      "ep number 148\n",
      "ep number 149\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 8        |\n",
      "| episodes                | 150      |\n",
      "| mean 100 episode reward | -213     |\n",
      "| steps                   | 29799    |\n",
      "--------------------------------------\n",
      "ep number 150\n",
      "ep number 151\n",
      "ep number 152\n",
      "ep number 153\n",
      "ep number 154\n",
      "ep number 155\n",
      "ep number 156\n",
      "ep number 157\n",
      "ep number 158\n",
      "ep number 159\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 160      |\n",
      "| mean 100 episode reward | -230     |\n",
      "| steps                   | 31799    |\n",
      "--------------------------------------\n",
      "ep number 160\n",
      "ep number 161\n",
      "ep number 162\n",
      "ep number 163\n",
      "ep number 164\n",
      "ep number 165\n",
      "ep number 166\n",
      "ep number 167\n",
      "ep number 168\n",
      "ep number 169\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 170      |\n",
      "| mean 100 episode reward | -240     |\n",
      "| steps                   | 33799    |\n",
      "--------------------------------------\n",
      "ep number 170\n",
      "ep number 171\n",
      "ep number 172\n",
      "ep number 173\n",
      "ep number 174\n",
      "ep number 175\n",
      "ep number 176\n",
      "ep number 177\n",
      "ep number 178\n",
      "ep number 179\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 180      |\n",
      "| mean 100 episode reward | -247     |\n",
      "| steps                   | 35799    |\n",
      "--------------------------------------\n",
      "ep number 180\n",
      "ep number 181\n",
      "ep number 182\n",
      "ep number 183\n",
      "ep number 184\n",
      "ep number 185\n",
      "ep number 186\n",
      "ep number 187\n",
      "ep number 188\n",
      "ep number 189\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 190      |\n",
      "| mean 100 episode reward | -262     |\n",
      "| steps                   | 37799    |\n",
      "--------------------------------------\n",
      "ep number 190\n",
      "ep number 191\n",
      "ep number 192\n",
      "ep number 193\n",
      "ep number 194\n",
      "ep number 195\n",
      "ep number 196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep number 197\n",
      "ep number 198\n",
      "ep number 199\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | -277     |\n",
      "| steps                   | 39799    |\n",
      "--------------------------------------\n",
      "ep number 200\n",
      "ep number 201\n",
      "ep number 202\n",
      "ep number 203\n",
      "ep number 204\n",
      "ep number 205\n",
      "ep number 206\n",
      "ep number 207\n",
      "ep number 208\n",
      "ep number 209\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 210      |\n",
      "| mean 100 episode reward | -276     |\n",
      "| steps                   | 41799    |\n",
      "--------------------------------------\n",
      "ep number 210\n",
      "ep number 211\n",
      "ep number 212\n",
      "ep number 213\n",
      "ep number 214\n",
      "ep number 215\n",
      "ep number 216\n",
      "ep number 217\n",
      "ep number 218\n",
      "ep number 219\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 220      |\n",
      "| mean 100 episode reward | -284     |\n",
      "| steps                   | 43799    |\n",
      "--------------------------------------\n",
      "ep number 220\n",
      "ep number 221\n",
      "ep number 222\n",
      "ep number 223\n",
      "ep number 224\n",
      "ep number 225\n",
      "ep number 226\n",
      "ep number 227\n",
      "ep number 228\n",
      "ep number 229\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 230      |\n",
      "| mean 100 episode reward | -291     |\n",
      "| steps                   | 45799    |\n",
      "--------------------------------------\n",
      "ep number 230\n",
      "ep number 231\n",
      "ep number 232\n",
      "ep number 233\n",
      "ep number 234\n",
      "ep number 235\n",
      "ep number 236\n",
      "ep number 237\n",
      "ep number 238\n",
      "ep number 239\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 240      |\n",
      "| mean 100 episode reward | -290     |\n",
      "| steps                   | 47799    |\n",
      "--------------------------------------\n",
      "ep number 240\n",
      "ep number 241\n",
      "ep number 242\n",
      "ep number 243\n",
      "ep number 244\n",
      "ep number 245\n",
      "ep number 246\n",
      "ep number 247\n",
      "ep number 248\n",
      "ep number 249\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 250      |\n",
      "| mean 100 episode reward | -288     |\n",
      "| steps                   | 49799    |\n",
      "--------------------------------------\n",
      "ep number 250\n",
      "ep number 251\n",
      "ep number 252\n",
      "ep number 253\n",
      "ep number 254\n",
      "ep number 255\n",
      "ep number 256\n",
      "ep number 257\n",
      "ep number 258\n",
      "ep number 259\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 260      |\n",
      "| mean 100 episode reward | -297     |\n",
      "| steps                   | 51799    |\n",
      "--------------------------------------\n",
      "ep number 260\n",
      "ep number 261\n",
      "ep number 262\n",
      "ep number 263\n",
      "ep number 264\n",
      "ep number 265\n",
      "ep number 266\n",
      "ep number 267\n",
      "ep number 268\n",
      "ep number 269\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 270      |\n",
      "| mean 100 episode reward | -302     |\n",
      "| steps                   | 53799    |\n",
      "--------------------------------------\n",
      "ep number 270\n",
      "ep number 271\n",
      "ep number 272\n",
      "ep number 273\n",
      "ep number 274\n",
      "ep number 275\n",
      "ep number 276\n",
      "ep number 277\n",
      "ep number 278\n",
      "ep number 279\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 280      |\n",
      "| mean 100 episode reward | -298     |\n",
      "| steps                   | 55799    |\n",
      "--------------------------------------\n",
      "ep number 280\n",
      "ep number 281\n",
      "ep number 282\n",
      "ep number 283\n",
      "ep number 284\n",
      "ep number 285\n",
      "ep number 286\n",
      "ep number 287\n",
      "ep number 288\n",
      "ep number 289\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 290      |\n",
      "| mean 100 episode reward | -282     |\n",
      "| steps                   | 57799    |\n",
      "--------------------------------------\n",
      "ep number 290\n",
      "ep number 291\n",
      "ep number 292\n",
      "ep number 293\n",
      "ep number 294\n",
      "ep number 295\n",
      "ep number 296\n",
      "ep number 297\n",
      "ep number 298\n",
      "ep number 299\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | -273     |\n",
      "| steps                   | 59799    |\n",
      "--------------------------------------\n",
      "ep number 300\n",
      "ep number 301\n",
      "ep number 302\n",
      "ep number 303\n",
      "ep number 304\n",
      "ep number 305\n",
      "ep number 306\n",
      "ep number 307\n",
      "ep number 308\n",
      "ep number 309\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 4        |\n",
      "| episodes                | 310      |\n",
      "| mean 100 episode reward | -258     |\n",
      "| steps                   | 61799    |\n",
      "--------------------------------------\n",
      "ep number 310\n",
      "ep number 311\n",
      "ep number 312\n",
      "ep number 313\n",
      "ep number 314\n",
      "ep number 315\n",
      "ep number 316\n",
      "ep number 317\n",
      "ep number 318\n",
      "ep number 319\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 4        |\n",
      "| episodes                | 320      |\n",
      "| mean 100 episode reward | -246     |\n",
      "| steps                   | 63799    |\n",
      "--------------------------------------\n",
      "ep number 320\n",
      "ep number 321\n",
      "ep number 322\n",
      "ep number 323\n",
      "ep number 324\n",
      "ep number 325\n",
      "ep number 326\n",
      "ep number 327\n",
      "ep number 328\n",
      "ep number 329\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 4        |\n",
      "| episodes                | 330      |\n",
      "| mean 100 episode reward | -234     |\n",
      "| steps                   | 65799    |\n",
      "--------------------------------------\n",
      "ep number 330\n",
      "ep number 331\n",
      "ep number 332\n",
      "ep number 333\n",
      "ep number 334\n",
      "ep number 335\n",
      "ep number 336\n",
      "ep number 337\n",
      "ep number 338\n",
      "ep number 339\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 4        |\n",
      "| episodes                | 340      |\n",
      "| mean 100 episode reward | -219     |\n",
      "| steps                   | 67799    |\n",
      "--------------------------------------\n",
      "ep number 340\n",
      "ep number 341\n",
      "ep number 342\n",
      "ep number 343\n",
      "ep number 344\n",
      "ep number 345\n",
      "ep number 346\n",
      "ep number 347\n",
      "ep number 348\n",
      "ep number 349\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 4        |\n",
      "| episodes                | 350      |\n",
      "| mean 100 episode reward | -209     |\n",
      "| steps                   | 69799    |\n",
      "--------------------------------------\n",
      "ep number 350\n",
      "ep number 351\n",
      "ep number 352\n",
      "ep number 353\n",
      "ep number 354\n",
      "ep number 355\n",
      "ep number 356\n",
      "ep number 357\n",
      "ep number 358\n",
      "ep number 359\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 360      |\n",
      "| mean 100 episode reward | -190     |\n",
      "| steps                   | 71799    |\n",
      "--------------------------------------\n",
      "ep number 360\n",
      "ep number 361\n",
      "ep number 362\n",
      "ep number 363\n",
      "ep number 364\n",
      "ep number 365\n",
      "ep number 366\n",
      "ep number 367\n",
      "ep number 368\n",
      "ep number 369\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 370      |\n",
      "| mean 100 episode reward | -178     |\n",
      "| steps                   | 73799    |\n",
      "--------------------------------------\n",
      "ep number 370\n",
      "ep number 371\n",
      "ep number 372\n",
      "ep number 373\n",
      "ep number 374\n",
      "ep number 375\n",
      "ep number 376\n",
      "ep number 377\n",
      "ep number 378\n",
      "ep number 379\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 380      |\n",
      "| mean 100 episode reward | -179     |\n",
      "| steps                   | 75799    |\n",
      "--------------------------------------\n",
      "ep number 380\n",
      "ep number 381\n",
      "ep number 382\n",
      "ep number 383\n",
      "ep number 384\n",
      "ep number 385\n",
      "ep number 386\n",
      "ep number 387\n",
      "ep number 388\n",
      "ep number 389\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 390      |\n",
      "| mean 100 episode reward | -197     |\n",
      "| steps                   | 77799    |\n",
      "--------------------------------------\n",
      "ep number 390\n",
      "ep number 391\n",
      "ep number 392\n",
      "ep number 393\n",
      "ep number 394\n",
      "ep number 395\n",
      "ep number 396\n",
      "ep number 397\n",
      "ep number 398\n",
      "ep number 399\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | -201     |\n",
      "| steps                   | 79799    |\n",
      "--------------------------------------\n",
      "ep number 400\n",
      "ep number 401\n",
      "ep number 402\n",
      "ep number 403\n",
      "ep number 404\n",
      "ep number 405\n",
      "ep number 406\n",
      "ep number 407\n",
      "ep number 408\n",
      "ep number 409\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 410      |\n",
      "| mean 100 episode reward | -207     |\n",
      "| steps                   | 81799    |\n",
      "--------------------------------------\n",
      "ep number 410\n",
      "ep number 411\n",
      "ep number 412\n",
      "ep number 413\n",
      "ep number 414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep number 415\n",
      "ep number 416\n",
      "ep number 417\n",
      "ep number 418\n",
      "ep number 419\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 420      |\n",
      "| mean 100 episode reward | -208     |\n",
      "| steps                   | 83799    |\n",
      "--------------------------------------\n",
      "ep number 420\n",
      "ep number 421\n",
      "ep number 422\n",
      "ep number 423\n",
      "ep number 424\n",
      "ep number 425\n",
      "ep number 426\n",
      "ep number 427\n",
      "ep number 428\n",
      "ep number 429\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 430      |\n",
      "| mean 100 episode reward | -213     |\n",
      "| steps                   | 85799    |\n",
      "--------------------------------------\n",
      "ep number 430\n",
      "ep number 431\n",
      "ep number 432\n",
      "ep number 433\n",
      "ep number 434\n",
      "ep number 435\n",
      "ep number 436\n",
      "ep number 437\n",
      "ep number 438\n",
      "ep number 439\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 440      |\n",
      "| mean 100 episode reward | -215     |\n",
      "| steps                   | 87799    |\n",
      "--------------------------------------\n",
      "ep number 440\n",
      "ep number 441\n",
      "ep number 442\n",
      "ep number 443\n",
      "ep number 444\n",
      "ep number 445\n",
      "ep number 446\n",
      "ep number 447\n",
      "ep number 448\n",
      "ep number 449\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 450      |\n",
      "| mean 100 episode reward | -220     |\n",
      "| steps                   | 89799    |\n",
      "--------------------------------------\n",
      "ep number 450\n",
      "ep number 451\n",
      "ep number 452\n",
      "ep number 453\n",
      "ep number 454\n",
      "ep number 455\n",
      "ep number 456\n",
      "ep number 457\n",
      "ep number 458\n",
      "ep number 459\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 460      |\n",
      "| mean 100 episode reward | -219     |\n",
      "| steps                   | 91799    |\n",
      "--------------------------------------\n",
      "ep number 460\n",
      "ep number 461\n",
      "ep number 462\n",
      "ep number 463\n",
      "ep number 464\n",
      "ep number 465\n",
      "ep number 466\n",
      "ep number 467\n",
      "ep number 468\n",
      "ep number 469\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 470      |\n",
      "| mean 100 episode reward | -225     |\n",
      "| steps                   | 93799    |\n",
      "--------------------------------------\n",
      "ep number 470\n",
      "ep number 471\n",
      "ep number 472\n",
      "ep number 473\n",
      "ep number 474\n",
      "ep number 475\n",
      "ep number 476\n",
      "ep number 477\n",
      "ep number 478\n",
      "ep number 479\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 480      |\n",
      "| mean 100 episode reward | -221     |\n",
      "| steps                   | 95799    |\n",
      "--------------------------------------\n",
      "ep number 480\n",
      "ep number 481\n",
      "ep number 482\n",
      "ep number 483\n",
      "ep number 484\n",
      "ep number 485\n",
      "ep number 486\n",
      "ep number 487\n",
      "ep number 488\n",
      "ep number 489\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 490      |\n",
      "| mean 100 episode reward | -234     |\n",
      "| steps                   | 97799    |\n",
      "--------------------------------------\n",
      "ep number 490\n",
      "ep number 491\n",
      "ep number 492\n",
      "ep number 493\n",
      "ep number 494\n",
      "ep number 495\n",
      "ep number 496\n",
      "ep number 497\n",
      "ep number 498\n",
      "ep number 499\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | -237     |\n",
      "| steps                   | 99799    |\n",
      "--------------------------------------\n",
      "ep number 500\n",
      "ep number 501\n",
      "ep number 502\n",
      "ep number 503\n",
      "ep number 504\n",
      "ep number 505\n",
      "ep number 506\n",
      "ep number 507\n",
      "ep number 508\n",
      "ep number 509\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 510      |\n",
      "| mean 100 episode reward | -246     |\n",
      "| steps                   | 101799   |\n",
      "--------------------------------------\n",
      "ep number 510\n",
      "ep number 511\n",
      "ep number 512\n",
      "ep number 513\n",
      "ep number 514\n",
      "ep number 515\n",
      "ep number 516\n",
      "ep number 517\n",
      "ep number 518\n",
      "ep number 519\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 520      |\n",
      "| mean 100 episode reward | -245     |\n",
      "| steps                   | 103799   |\n",
      "--------------------------------------\n",
      "ep number 520\n",
      "ep number 521\n",
      "ep number 522\n",
      "ep number 523\n",
      "ep number 524\n",
      "ep number 525\n",
      "ep number 526\n",
      "ep number 527\n",
      "ep number 528\n",
      "ep number 529\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 530      |\n",
      "| mean 100 episode reward | -250     |\n",
      "| steps                   | 105799   |\n",
      "--------------------------------------\n",
      "ep number 530\n",
      "ep number 531\n",
      "ep number 532\n",
      "ep number 533\n",
      "ep number 534\n",
      "ep number 535\n",
      "ep number 536\n",
      "ep number 537\n",
      "ep number 538\n",
      "ep number 539\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 540      |\n",
      "| mean 100 episode reward | -258     |\n",
      "| steps                   | 107799   |\n",
      "--------------------------------------\n",
      "ep number 540\n",
      "ep number 541\n",
      "ep number 542\n",
      "ep number 543\n",
      "ep number 544\n",
      "ep number 545\n",
      "ep number 546\n",
      "ep number 547\n",
      "ep number 548\n",
      "ep number 549\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 550      |\n",
      "| mean 100 episode reward | -254     |\n",
      "| steps                   | 109799   |\n",
      "--------------------------------------\n",
      "ep number 550\n",
      "ep number 551\n",
      "ep number 552\n",
      "ep number 553\n",
      "ep number 554\n",
      "ep number 555\n",
      "ep number 556\n",
      "ep number 557\n",
      "ep number 558\n",
      "ep number 559\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 560      |\n",
      "| mean 100 episode reward | -261     |\n",
      "| steps                   | 111799   |\n",
      "--------------------------------------\n",
      "ep number 560\n",
      "ep number 561\n",
      "ep number 562\n",
      "ep number 563\n",
      "ep number 564\n",
      "ep number 565\n",
      "ep number 566\n",
      "ep number 567\n",
      "ep number 568\n",
      "ep number 569\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 570      |\n",
      "| mean 100 episode reward | -264     |\n",
      "| steps                   | 113799   |\n",
      "--------------------------------------\n",
      "ep number 570\n",
      "ep number 571\n",
      "ep number 572\n",
      "ep number 573\n",
      "ep number 574\n",
      "ep number 575\n",
      "ep number 576\n",
      "ep number 577\n",
      "ep number 578\n",
      "ep number 579\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 580      |\n",
      "| mean 100 episode reward | -272     |\n",
      "| steps                   | 115799   |\n",
      "--------------------------------------\n",
      "ep number 580\n",
      "ep number 581\n",
      "ep number 582\n",
      "ep number 583\n",
      "ep number 584\n",
      "ep number 585\n",
      "ep number 586\n",
      "ep number 587\n",
      "ep number 588\n",
      "ep number 589\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 590      |\n",
      "| mean 100 episode reward | -262     |\n",
      "| steps                   | 117799   |\n",
      "--------------------------------------\n",
      "ep number 590\n",
      "ep number 591\n",
      "ep number 592\n",
      "ep number 593\n",
      "ep number 594\n",
      "ep number 595\n",
      "ep number 596\n",
      "ep number 597\n",
      "ep number 598\n",
      "ep number 599\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | -252     |\n",
      "| steps                   | 119799   |\n",
      "--------------------------------------\n",
      "ep number 600\n",
      "ep number 601\n",
      "ep number 602\n",
      "ep number 603\n",
      "ep number 604\n",
      "ep number 605\n",
      "ep number 606\n",
      "ep number 607\n",
      "ep number 608\n",
      "ep number 609\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 610      |\n",
      "| mean 100 episode reward | -246     |\n",
      "| steps                   | 121799   |\n",
      "--------------------------------------\n",
      "ep number 610\n",
      "ep number 611\n",
      "ep number 612\n",
      "ep number 613\n",
      "ep number 614\n",
      "ep number 615\n",
      "ep number 616\n",
      "ep number 617\n",
      "ep number 618\n",
      "ep number 619\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 620      |\n",
      "| mean 100 episode reward | -246     |\n",
      "| steps                   | 123799   |\n",
      "--------------------------------------\n",
      "ep number 620\n",
      "ep number 621\n",
      "ep number 622\n",
      "ep number 623\n",
      "ep number 624\n",
      "ep number 625\n",
      "ep number 626\n",
      "ep number 627\n",
      "ep number 628\n",
      "ep number 629\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 630      |\n",
      "| mean 100 episode reward | -244     |\n",
      "| steps                   | 125799   |\n",
      "--------------------------------------\n",
      "ep number 630\n",
      "ep number 631\n",
      "ep number 632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep number 633\n",
      "ep number 634\n",
      "ep number 635\n",
      "ep number 636\n",
      "ep number 637\n",
      "ep number 638\n",
      "ep number 639\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 640      |\n",
      "| mean 100 episode reward | -245     |\n",
      "| steps                   | 127799   |\n",
      "--------------------------------------\n",
      "ep number 640\n",
      "ep number 641\n",
      "ep number 642\n",
      "ep number 643\n",
      "ep number 644\n",
      "ep number 645\n",
      "ep number 646\n",
      "ep number 647\n",
      "ep number 648\n",
      "ep number 649\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 650      |\n",
      "| mean 100 episode reward | -244     |\n",
      "| steps                   | 129799   |\n",
      "--------------------------------------\n",
      "ep number 650\n",
      "ep number 651\n",
      "ep number 652\n",
      "ep number 653\n",
      "ep number 654\n",
      "ep number 655\n",
      "ep number 656\n",
      "ep number 657\n",
      "ep number 658\n",
      "ep number 659\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 660      |\n",
      "| mean 100 episode reward | -235     |\n",
      "| steps                   | 131799   |\n",
      "--------------------------------------\n",
      "ep number 660\n",
      "ep number 661\n",
      "ep number 662\n",
      "ep number 663\n",
      "ep number 664\n",
      "ep number 665\n",
      "ep number 666\n",
      "ep number 667\n",
      "ep number 668\n",
      "ep number 669\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 670      |\n",
      "| mean 100 episode reward | -224     |\n",
      "| steps                   | 133799   |\n",
      "--------------------------------------\n",
      "ep number 670\n",
      "ep number 671\n",
      "ep number 672\n",
      "ep number 673\n",
      "ep number 674\n",
      "ep number 675\n",
      "ep number 676\n",
      "ep number 677\n",
      "ep number 678\n",
      "ep number 679\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 680      |\n",
      "| mean 100 episode reward | -220     |\n",
      "| steps                   | 135799   |\n",
      "--------------------------------------\n",
      "ep number 680\n",
      "ep number 681\n",
      "ep number 682\n",
      "ep number 683\n",
      "ep number 684\n",
      "ep number 685\n",
      "ep number 686\n",
      "ep number 687\n",
      "ep number 688\n",
      "ep number 689\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 690      |\n",
      "| mean 100 episode reward | -214     |\n",
      "| steps                   | 137799   |\n",
      "--------------------------------------\n",
      "ep number 690\n",
      "ep number 691\n",
      "ep number 692\n",
      "ep number 693\n",
      "ep number 694\n",
      "ep number 695\n",
      "ep number 696\n",
      "ep number 697\n",
      "ep number 698\n",
      "ep number 699\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | -212     |\n",
      "| steps                   | 139799   |\n",
      "--------------------------------------\n",
      "ep number 700\n",
      "ep number 701\n",
      "ep number 702\n",
      "ep number 703\n",
      "ep number 704\n",
      "ep number 705\n",
      "ep number 706\n",
      "ep number 707\n",
      "ep number 708\n",
      "ep number 709\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 710      |\n",
      "| mean 100 episode reward | -213     |\n",
      "| steps                   | 141799   |\n",
      "--------------------------------------\n",
      "ep number 710\n",
      "ep number 711\n",
      "ep number 712\n",
      "ep number 713\n",
      "ep number 714\n",
      "ep number 715\n",
      "ep number 716\n",
      "ep number 717\n",
      "ep number 718\n",
      "ep number 719\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 720      |\n",
      "| mean 100 episode reward | -217     |\n",
      "| steps                   | 143799   |\n",
      "--------------------------------------\n",
      "ep number 720\n",
      "ep number 721\n",
      "ep number 722\n",
      "ep number 723\n",
      "ep number 724\n",
      "ep number 725\n",
      "ep number 726\n",
      "ep number 727\n",
      "ep number 728\n",
      "ep number 729\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 730      |\n",
      "| mean 100 episode reward | -217     |\n",
      "| steps                   | 145799   |\n",
      "--------------------------------------\n",
      "ep number 730\n",
      "ep number 731\n",
      "ep number 732\n",
      "ep number 733\n",
      "ep number 734\n",
      "ep number 735\n",
      "ep number 736\n",
      "ep number 737\n",
      "ep number 738\n",
      "ep number 739\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 740      |\n",
      "| mean 100 episode reward | -222     |\n",
      "| steps                   | 147799   |\n",
      "--------------------------------------\n",
      "ep number 740\n",
      "ep number 741\n",
      "ep number 742\n",
      "ep number 743\n",
      "ep number 744\n",
      "ep number 745\n",
      "ep number 746\n",
      "ep number 747\n",
      "ep number 748\n",
      "ep number 749\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 750      |\n",
      "| mean 100 episode reward | -223     |\n",
      "| steps                   | 149799   |\n",
      "--------------------------------------\n",
      "ep number 750\n",
      "ep number 751\n",
      "ep number 752\n",
      "ep number 753\n",
      "ep number 754\n",
      "ep number 755\n",
      "ep number 756\n",
      "ep number 757\n",
      "ep number 758\n",
      "ep number 759\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 760      |\n",
      "| mean 100 episode reward | -222     |\n",
      "| steps                   | 151799   |\n",
      "--------------------------------------\n",
      "ep number 760\n",
      "ep number 761\n",
      "ep number 762\n",
      "ep number 763\n",
      "ep number 764\n",
      "ep number 765\n",
      "ep number 766\n",
      "ep number 767\n",
      "ep number 768\n",
      "ep number 769\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 770      |\n",
      "| mean 100 episode reward | -228     |\n",
      "| steps                   | 153799   |\n",
      "--------------------------------------\n",
      "ep number 770\n",
      "ep number 771\n",
      "ep number 772\n",
      "ep number 773\n",
      "ep number 774\n",
      "ep number 775\n",
      "ep number 776\n",
      "ep number 777\n",
      "ep number 778\n",
      "ep number 779\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 780      |\n",
      "| mean 100 episode reward | -224     |\n",
      "| steps                   | 155799   |\n",
      "--------------------------------------\n",
      "ep number 780\n",
      "ep number 781\n",
      "ep number 782\n",
      "ep number 783\n",
      "ep number 784\n",
      "ep number 785\n",
      "ep number 786\n",
      "ep number 787\n",
      "ep number 788\n",
      "ep number 789\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 790      |\n",
      "| mean 100 episode reward | -209     |\n",
      "| steps                   | 157799   |\n",
      "--------------------------------------\n",
      "ep number 790\n",
      "ep number 791\n",
      "ep number 792\n",
      "ep number 793\n",
      "ep number 794\n",
      "ep number 795\n",
      "ep number 796\n",
      "ep number 797\n",
      "ep number 798\n",
      "ep number 799\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | -207     |\n",
      "| steps                   | 159799   |\n",
      "--------------------------------------\n",
      "ep number 800\n",
      "ep number 801\n",
      "ep number 802\n",
      "ep number 803\n",
      "ep number 804\n",
      "ep number 805\n",
      "ep number 806\n",
      "ep number 807\n",
      "ep number 808\n",
      "ep number 809\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 810      |\n",
      "| mean 100 episode reward | -209     |\n",
      "| steps                   | 161799   |\n",
      "--------------------------------------\n",
      "ep number 810\n",
      "ep number 811\n",
      "ep number 812\n",
      "ep number 813\n",
      "ep number 814\n",
      "ep number 815\n",
      "ep number 816\n",
      "ep number 817\n",
      "ep number 818\n",
      "ep number 819\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 820      |\n",
      "| mean 100 episode reward | -203     |\n",
      "| steps                   | 163799   |\n",
      "--------------------------------------\n",
      "ep number 820\n",
      "ep number 821\n",
      "ep number 822\n",
      "ep number 823\n",
      "ep number 824\n",
      "ep number 825\n",
      "ep number 826\n",
      "ep number 827\n",
      "ep number 828\n",
      "ep number 829\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 830      |\n",
      "| mean 100 episode reward | -200     |\n",
      "| steps                   | 165799   |\n",
      "--------------------------------------\n",
      "ep number 830\n",
      "ep number 831\n",
      "ep number 832\n",
      "ep number 833\n",
      "ep number 834\n",
      "ep number 835\n",
      "ep number 836\n",
      "ep number 837\n",
      "ep number 838\n",
      "ep number 839\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 840      |\n",
      "| mean 100 episode reward | -188     |\n",
      "| steps                   | 167799   |\n",
      "--------------------------------------\n",
      "ep number 840\n",
      "ep number 841\n",
      "ep number 842\n",
      "ep number 843\n",
      "ep number 844\n",
      "ep number 845\n",
      "ep number 846\n",
      "ep number 847\n",
      "ep number 848\n",
      "ep number 849\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 850      |\n",
      "| mean 100 episode reward | -183     |\n",
      "| steps                   | 169799   |\n",
      "--------------------------------------\n",
      "ep number 850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep number 851\n",
      "ep number 852\n",
      "ep number 853\n",
      "ep number 854\n",
      "ep number 855\n",
      "ep number 856\n",
      "ep number 857\n",
      "ep number 858\n",
      "ep number 859\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 860      |\n",
      "| mean 100 episode reward | -192     |\n",
      "| steps                   | 171799   |\n",
      "--------------------------------------\n",
      "ep number 860\n",
      "ep number 861\n",
      "ep number 862\n",
      "ep number 863\n",
      "ep number 864\n",
      "ep number 865\n",
      "ep number 866\n",
      "ep number 867\n",
      "ep number 868\n",
      "ep number 869\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 870      |\n",
      "| mean 100 episode reward | -190     |\n",
      "| steps                   | 173799   |\n",
      "--------------------------------------\n",
      "ep number 870\n",
      "ep number 871\n",
      "ep number 872\n",
      "ep number 873\n",
      "ep number 874\n",
      "ep number 875\n",
      "ep number 876\n",
      "ep number 877\n",
      "ep number 878\n",
      "ep number 879\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 880      |\n",
      "| mean 100 episode reward | -185     |\n",
      "| steps                   | 175799   |\n",
      "--------------------------------------\n",
      "ep number 880\n",
      "ep number 881\n",
      "ep number 882\n",
      "ep number 883\n",
      "ep number 884\n",
      "ep number 885\n",
      "ep number 886\n",
      "ep number 887\n",
      "ep number 888\n",
      "ep number 889\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 890      |\n",
      "| mean 100 episode reward | -191     |\n",
      "| steps                   | 177799   |\n",
      "--------------------------------------\n",
      "ep number 890\n",
      "ep number 891\n",
      "ep number 892\n",
      "ep number 893\n",
      "ep number 894\n",
      "ep number 895\n",
      "ep number 896\n",
      "ep number 897\n",
      "ep number 898\n",
      "ep number 899\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | -202     |\n",
      "| steps                   | 179799   |\n",
      "--------------------------------------\n",
      "ep number 900\n",
      "ep number 901\n",
      "ep number 902\n",
      "ep number 903\n",
      "ep number 904\n",
      "ep number 905\n",
      "ep number 906\n",
      "ep number 907\n",
      "ep number 908\n",
      "ep number 909\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 910      |\n",
      "| mean 100 episode reward | -204     |\n",
      "| steps                   | 181799   |\n",
      "--------------------------------------\n",
      "ep number 910\n",
      "ep number 911\n",
      "ep number 912\n",
      "ep number 913\n",
      "ep number 914\n",
      "ep number 915\n",
      "ep number 916\n",
      "ep number 917\n",
      "ep number 918\n",
      "ep number 919\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 920      |\n",
      "| mean 100 episode reward | -208     |\n",
      "| steps                   | 183799   |\n",
      "--------------------------------------\n",
      "ep number 920\n",
      "ep number 921\n",
      "ep number 922\n",
      "ep number 923\n",
      "ep number 924\n",
      "ep number 925\n",
      "ep number 926\n",
      "ep number 927\n",
      "ep number 928\n",
      "ep number 929\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 930      |\n",
      "| mean 100 episode reward | -219     |\n",
      "| steps                   | 185799   |\n",
      "--------------------------------------\n",
      "ep number 930\n",
      "ep number 931\n",
      "ep number 932\n",
      "ep number 933\n",
      "ep number 934\n",
      "ep number 935\n",
      "ep number 936\n",
      "ep number 937\n",
      "ep number 938\n",
      "ep number 939\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 940      |\n",
      "| mean 100 episode reward | -238     |\n",
      "| steps                   | 187799   |\n",
      "--------------------------------------\n",
      "ep number 940\n",
      "ep number 941\n",
      "ep number 942\n",
      "ep number 943\n",
      "ep number 944\n",
      "ep number 945\n",
      "ep number 946\n",
      "ep number 947\n",
      "ep number 948\n",
      "ep number 949\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 950      |\n",
      "| mean 100 episode reward | -258     |\n",
      "| steps                   | 189799   |\n",
      "--------------------------------------\n",
      "ep number 950\n",
      "ep number 951\n",
      "ep number 952\n",
      "ep number 953\n",
      "ep number 954\n",
      "ep number 955\n",
      "ep number 956\n",
      "ep number 957\n",
      "ep number 958\n",
      "ep number 959\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 960      |\n",
      "| mean 100 episode reward | -254     |\n",
      "| steps                   | 191799   |\n",
      "--------------------------------------\n",
      "ep number 960\n",
      "ep number 961\n",
      "ep number 962\n",
      "ep number 963\n",
      "ep number 964\n",
      "ep number 965\n",
      "ep number 966\n",
      "ep number 967\n",
      "ep number 968\n",
      "ep number 969\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 970      |\n",
      "| mean 100 episode reward | -253     |\n",
      "| steps                   | 193799   |\n",
      "--------------------------------------\n",
      "ep number 970\n",
      "ep number 971\n",
      "ep number 972\n",
      "ep number 973\n",
      "ep number 974\n",
      "ep number 975\n",
      "ep number 976\n",
      "ep number 977\n",
      "ep number 978\n",
      "ep number 979\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 980      |\n",
      "| mean 100 episode reward | -252     |\n",
      "| steps                   | 195799   |\n",
      "--------------------------------------\n",
      "ep number 980\n",
      "ep number 981\n",
      "ep number 982\n",
      "ep number 983\n",
      "ep number 984\n",
      "ep number 985\n",
      "ep number 986\n",
      "ep number 987\n",
      "ep number 988\n",
      "ep number 989\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 990      |\n",
      "| mean 100 episode reward | -259     |\n",
      "| steps                   | 197799   |\n",
      "--------------------------------------\n",
      "ep number 990\n",
      "ep number 991\n",
      "ep number 992\n",
      "ep number 993\n",
      "ep number 994\n",
      "ep number 995\n",
      "ep number 996\n",
      "ep number 997\n",
      "ep number 998\n",
      "ep number 999\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | -264     |\n",
      "| steps                   | 199799   |\n",
      "--------------------------------------\n",
      "ep number 1000\n",
      "ep number 1001\n",
      "ep number 1002\n",
      "ep number 1003\n",
      "ep number 1004\n",
      "ep number 1005\n",
      "ep number 1006\n",
      "ep number 1007\n",
      "ep number 1008\n",
      "ep number 1009\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1010     |\n",
      "| mean 100 episode reward | -262     |\n",
      "| steps                   | 201799   |\n",
      "--------------------------------------\n",
      "ep number 1010\n",
      "ep number 1011\n",
      "ep number 1012\n",
      "ep number 1013\n",
      "ep number 1014\n",
      "ep number 1015\n",
      "ep number 1016\n",
      "ep number 1017\n",
      "ep number 1018\n",
      "ep number 1019\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1020     |\n",
      "| mean 100 episode reward | -266     |\n",
      "| steps                   | 203799   |\n",
      "--------------------------------------\n",
      "ep number 1020\n",
      "ep number 1021\n",
      "ep number 1022\n",
      "ep number 1023\n",
      "ep number 1024\n",
      "ep number 1025\n",
      "ep number 1026\n",
      "ep number 1027\n",
      "ep number 1028\n",
      "ep number 1029\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1030     |\n",
      "| mean 100 episode reward | -268     |\n",
      "| steps                   | 205799   |\n",
      "--------------------------------------\n",
      "ep number 1030\n",
      "ep number 1031\n",
      "ep number 1032\n",
      "ep number 1033\n",
      "ep number 1034\n",
      "ep number 1035\n",
      "ep number 1036\n",
      "ep number 1037\n",
      "ep number 1038\n",
      "ep number 1039\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1040     |\n",
      "| mean 100 episode reward | -261     |\n",
      "| steps                   | 207799   |\n",
      "--------------------------------------\n",
      "ep number 1040\n",
      "ep number 1041\n",
      "ep number 1042\n",
      "ep number 1043\n",
      "ep number 1044\n",
      "ep number 1045\n",
      "ep number 1046\n",
      "ep number 1047\n",
      "ep number 1048\n",
      "ep number 1049\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1050     |\n",
      "| mean 100 episode reward | -247     |\n",
      "| steps                   | 209799   |\n",
      "--------------------------------------\n",
      "ep number 1050\n",
      "ep number 1051\n",
      "ep number 1052\n",
      "ep number 1053\n",
      "ep number 1054\n",
      "ep number 1055\n",
      "ep number 1056\n",
      "ep number 1057\n",
      "ep number 1058\n",
      "ep number 1059\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1060     |\n",
      "| mean 100 episode reward | -244     |\n",
      "| steps                   | 211799   |\n",
      "--------------------------------------\n",
      "ep number 1060\n",
      "ep number 1061\n",
      "ep number 1062\n",
      "ep number 1063\n",
      "ep number 1064\n",
      "ep number 1065\n",
      "ep number 1066\n",
      "ep number 1067\n",
      "ep number 1068\n",
      "ep number 1069\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1070     |\n",
      "| mean 100 episode reward | -252     |\n",
      "| steps                   | 213799   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep number 1070\n",
      "ep number 1071\n",
      "ep number 1072\n",
      "ep number 1073\n",
      "ep number 1074\n",
      "ep number 1075\n",
      "ep number 1076\n",
      "ep number 1077\n",
      "ep number 1078\n",
      "ep number 1079\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1080     |\n",
      "| mean 100 episode reward | -257     |\n",
      "| steps                   | 215799   |\n",
      "--------------------------------------\n",
      "ep number 1080\n",
      "ep number 1081\n",
      "ep number 1082\n",
      "ep number 1083\n",
      "ep number 1084\n",
      "ep number 1085\n",
      "ep number 1086\n",
      "ep number 1087\n",
      "ep number 1088\n",
      "ep number 1089\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1090     |\n",
      "| mean 100 episode reward | -258     |\n",
      "| steps                   | 217799   |\n",
      "--------------------------------------\n",
      "ep number 1090\n",
      "ep number 1091\n",
      "ep number 1092\n",
      "ep number 1093\n",
      "ep number 1094\n",
      "ep number 1095\n",
      "ep number 1096\n",
      "ep number 1097\n",
      "ep number 1098\n",
      "ep number 1099\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1100     |\n",
      "| mean 100 episode reward | -247     |\n",
      "| steps                   | 219799   |\n",
      "--------------------------------------\n",
      "ep number 1100\n",
      "ep number 1101\n",
      "ep number 1102\n",
      "ep number 1103\n",
      "ep number 1104\n",
      "ep number 1105\n",
      "ep number 1106\n",
      "ep number 1107\n",
      "ep number 1108\n",
      "ep number 1109\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1110     |\n",
      "| mean 100 episode reward | -251     |\n",
      "| steps                   | 221799   |\n",
      "--------------------------------------\n",
      "ep number 1110\n",
      "ep number 1111\n",
      "ep number 1112\n",
      "ep number 1113\n",
      "ep number 1114\n",
      "ep number 1115\n",
      "ep number 1116\n",
      "ep number 1117\n",
      "ep number 1118\n",
      "ep number 1119\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1120     |\n",
      "| mean 100 episode reward | -251     |\n",
      "| steps                   | 223799   |\n",
      "--------------------------------------\n",
      "ep number 1120\n",
      "ep number 1121\n",
      "ep number 1122\n",
      "ep number 1123\n",
      "ep number 1124\n",
      "ep number 1125\n",
      "ep number 1126\n",
      "ep number 1127\n",
      "ep number 1128\n",
      "ep number 1129\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1130     |\n",
      "| mean 100 episode reward | -229     |\n",
      "| steps                   | 225799   |\n",
      "--------------------------------------\n",
      "ep number 1130\n",
      "ep number 1131\n",
      "ep number 1132\n",
      "ep number 1133\n",
      "ep number 1134\n",
      "ep number 1135\n",
      "ep number 1136\n",
      "ep number 1137\n",
      "ep number 1138\n",
      "ep number 1139\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1140     |\n",
      "| mean 100 episode reward | -225     |\n",
      "| steps                   | 227799   |\n",
      "--------------------------------------\n",
      "ep number 1140\n",
      "ep number 1141\n",
      "ep number 1142\n",
      "ep number 1143\n",
      "ep number 1144\n",
      "ep number 1145\n",
      "ep number 1146\n",
      "ep number 1147\n",
      "ep number 1148\n",
      "ep number 1149\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1150     |\n",
      "| mean 100 episode reward | -222     |\n",
      "| steps                   | 229799   |\n",
      "--------------------------------------\n",
      "ep number 1150\n",
      "ep number 1151\n",
      "ep number 1152\n",
      "ep number 1153\n",
      "ep number 1154\n",
      "ep number 1155\n",
      "ep number 1156\n",
      "ep number 1157\n",
      "ep number 1158\n",
      "ep number 1159\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1160     |\n",
      "| mean 100 episode reward | -234     |\n",
      "| steps                   | 231799   |\n",
      "--------------------------------------\n",
      "ep number 1160\n",
      "ep number 1161\n",
      "ep number 1162\n",
      "ep number 1163\n",
      "ep number 1164\n",
      "ep number 1165\n",
      "ep number 1166\n",
      "ep number 1167\n",
      "ep number 1168\n",
      "ep number 1169\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1170     |\n",
      "| mean 100 episode reward | -234     |\n",
      "| steps                   | 233799   |\n",
      "--------------------------------------\n",
      "ep number 1170\n",
      "ep number 1171\n",
      "ep number 1172\n",
      "ep number 1173\n",
      "ep number 1174\n",
      "ep number 1175\n",
      "ep number 1176\n",
      "ep number 1177\n",
      "ep number 1178\n",
      "ep number 1179\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1180     |\n",
      "| mean 100 episode reward | -240     |\n",
      "| steps                   | 235799   |\n",
      "--------------------------------------\n",
      "ep number 1180\n",
      "ep number 1181\n",
      "ep number 1182\n",
      "ep number 1183\n",
      "ep number 1184\n",
      "ep number 1185\n",
      "ep number 1186\n",
      "ep number 1187\n",
      "ep number 1188\n",
      "ep number 1189\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1190     |\n",
      "| mean 100 episode reward | -244     |\n",
      "| steps                   | 237799   |\n",
      "--------------------------------------\n",
      "ep number 1190\n",
      "ep number 1191\n",
      "ep number 1192\n",
      "ep number 1193\n",
      "ep number 1194\n",
      "ep number 1195\n",
      "ep number 1196\n",
      "ep number 1197\n",
      "ep number 1198\n",
      "ep number 1199\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1200     |\n",
      "| mean 100 episode reward | -249     |\n",
      "| steps                   | 239799   |\n",
      "--------------------------------------\n",
      "ep number 1200\n",
      "ep number 1201\n",
      "ep number 1202\n",
      "ep number 1203\n",
      "ep number 1204\n",
      "ep number 1205\n",
      "ep number 1206\n",
      "ep number 1207\n",
      "ep number 1208\n",
      "ep number 1209\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1210     |\n",
      "| mean 100 episode reward | -236     |\n",
      "| steps                   | 241799   |\n",
      "--------------------------------------\n",
      "ep number 1210\n",
      "ep number 1211\n",
      "ep number 1212\n",
      "ep number 1213\n",
      "ep number 1214\n",
      "ep number 1215\n",
      "ep number 1216\n",
      "ep number 1217\n",
      "ep number 1218\n",
      "ep number 1219\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1220     |\n",
      "| mean 100 episode reward | -238     |\n",
      "| steps                   | 243799   |\n",
      "--------------------------------------\n",
      "ep number 1220\n",
      "ep number 1221\n",
      "ep number 1222\n",
      "ep number 1223\n",
      "ep number 1224\n",
      "ep number 1225\n",
      "ep number 1226\n",
      "ep number 1227\n",
      "ep number 1228\n",
      "ep number 1229\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1230     |\n",
      "| mean 100 episode reward | -252     |\n",
      "| steps                   | 245799   |\n",
      "--------------------------------------\n",
      "ep number 1230\n",
      "ep number 1231\n",
      "ep number 1232\n",
      "ep number 1233\n",
      "ep number 1234\n",
      "ep number 1235\n",
      "ep number 1236\n",
      "ep number 1237\n",
      "ep number 1238\n",
      "ep number 1239\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1240     |\n",
      "| mean 100 episode reward | -258     |\n",
      "| steps                   | 247799   |\n",
      "--------------------------------------\n",
      "ep number 1240\n",
      "ep number 1241\n",
      "ep number 1242\n",
      "ep number 1243\n",
      "ep number 1244\n",
      "ep number 1245\n",
      "ep number 1246\n",
      "ep number 1247\n",
      "ep number 1248\n",
      "ep number 1249\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1250     |\n",
      "| mean 100 episode reward | -256     |\n",
      "| steps                   | 249799   |\n",
      "--------------------------------------\n",
      "ep number 1250\n",
      "ep number 1251\n",
      "ep number 1252\n",
      "ep number 1253\n",
      "ep number 1254\n",
      "ep number 1255\n",
      "ep number 1256\n",
      "ep number 1257\n",
      "ep number 1258\n",
      "ep number 1259\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1260     |\n",
      "| mean 100 episode reward | -247     |\n",
      "| steps                   | 251799   |\n",
      "--------------------------------------\n",
      "ep number 1260\n",
      "ep number 1261\n",
      "ep number 1262\n",
      "ep number 1263\n",
      "ep number 1264\n",
      "ep number 1265\n",
      "ep number 1266\n",
      "ep number 1267\n",
      "ep number 1268\n",
      "ep number 1269\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1270     |\n",
      "| mean 100 episode reward | -239     |\n",
      "| steps                   | 253799   |\n",
      "--------------------------------------\n",
      "ep number 1270\n",
      "ep number 1271\n",
      "ep number 1272\n",
      "ep number 1273\n",
      "ep number 1274\n",
      "ep number 1275\n",
      "ep number 1276\n",
      "ep number 1277\n",
      "ep number 1278\n",
      "ep number 1279\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1280     |\n",
      "| mean 100 episode reward | -232     |\n",
      "| steps                   | 255799   |\n",
      "--------------------------------------\n",
      "ep number 1280\n",
      "ep number 1281\n",
      "ep number 1282\n",
      "ep number 1283\n",
      "ep number 1284\n",
      "ep number 1285\n",
      "ep number 1286\n",
      "ep number 1287\n",
      "ep number 1288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep number 1289\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1290     |\n",
      "| mean 100 episode reward | -226     |\n",
      "| steps                   | 257799   |\n",
      "--------------------------------------\n",
      "ep number 1290\n",
      "ep number 1291\n",
      "ep number 1292\n",
      "ep number 1293\n",
      "ep number 1294\n",
      "ep number 1295\n",
      "ep number 1296\n",
      "ep number 1297\n",
      "ep number 1298\n",
      "ep number 1299\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1300     |\n",
      "| mean 100 episode reward | -226     |\n",
      "| steps                   | 259799   |\n",
      "--------------------------------------\n",
      "ep number 1300\n",
      "ep number 1301\n",
      "ep number 1302\n",
      "ep number 1303\n",
      "ep number 1304\n",
      "ep number 1305\n",
      "ep number 1306\n",
      "ep number 1307\n",
      "ep number 1308\n",
      "ep number 1309\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1310     |\n",
      "| mean 100 episode reward | -239     |\n",
      "| steps                   | 261799   |\n",
      "--------------------------------------\n",
      "ep number 1310\n",
      "ep number 1311\n",
      "ep number 1312\n",
      "ep number 1313\n",
      "ep number 1314\n",
      "ep number 1315\n",
      "ep number 1316\n",
      "ep number 1317\n",
      "ep number 1318\n",
      "ep number 1319\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1320     |\n",
      "| mean 100 episode reward | -239     |\n",
      "| steps                   | 263799   |\n",
      "--------------------------------------\n",
      "ep number 1320\n",
      "ep number 1321\n",
      "ep number 1322\n",
      "ep number 1323\n",
      "ep number 1324\n",
      "ep number 1325\n",
      "ep number 1326\n",
      "ep number 1327\n",
      "ep number 1328\n",
      "ep number 1329\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1330     |\n",
      "| mean 100 episode reward | -238     |\n",
      "| steps                   | 265799   |\n",
      "--------------------------------------\n",
      "ep number 1330\n",
      "ep number 1331\n",
      "ep number 1332\n",
      "ep number 1333\n",
      "ep number 1334\n",
      "ep number 1335\n",
      "ep number 1336\n",
      "ep number 1337\n",
      "ep number 1338\n",
      "ep number 1339\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1340     |\n",
      "| mean 100 episode reward | -228     |\n",
      "| steps                   | 267799   |\n",
      "--------------------------------------\n",
      "ep number 1340\n",
      "ep number 1341\n",
      "ep number 1342\n",
      "ep number 1343\n",
      "ep number 1344\n",
      "ep number 1345\n",
      "ep number 1346\n",
      "ep number 1347\n",
      "ep number 1348\n",
      "ep number 1349\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1350     |\n",
      "| mean 100 episode reward | -231     |\n",
      "| steps                   | 269799   |\n",
      "--------------------------------------\n",
      "ep number 1350\n",
      "ep number 1351\n",
      "ep number 1352\n",
      "ep number 1353\n",
      "ep number 1354\n",
      "ep number 1355\n",
      "ep number 1356\n",
      "ep number 1357\n",
      "ep number 1358\n",
      "ep number 1359\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1360     |\n",
      "| mean 100 episode reward | -230     |\n",
      "| steps                   | 271799   |\n",
      "--------------------------------------\n",
      "ep number 1360\n",
      "ep number 1361\n",
      "ep number 1362\n",
      "ep number 1363\n",
      "ep number 1364\n",
      "ep number 1365\n",
      "ep number 1366\n",
      "ep number 1367\n",
      "ep number 1368\n",
      "ep number 1369\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1370     |\n",
      "| mean 100 episode reward | -226     |\n",
      "| steps                   | 273799   |\n",
      "--------------------------------------\n",
      "ep number 1370\n",
      "ep number 1371\n",
      "ep number 1372\n",
      "ep number 1373\n",
      "ep number 1374\n",
      "ep number 1375\n",
      "ep number 1376\n",
      "ep number 1377\n",
      "ep number 1378\n",
      "ep number 1379\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1380     |\n",
      "| mean 100 episode reward | -223     |\n",
      "| steps                   | 275799   |\n",
      "--------------------------------------\n",
      "ep number 1380\n",
      "ep number 1381\n",
      "ep number 1382\n",
      "ep number 1383\n",
      "ep number 1384\n",
      "ep number 1385\n",
      "ep number 1386\n",
      "ep number 1387\n",
      "ep number 1388\n",
      "ep number 1389\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1390     |\n",
      "| mean 100 episode reward | -223     |\n",
      "| steps                   | 277799   |\n",
      "--------------------------------------\n",
      "ep number 1390\n",
      "ep number 1391\n",
      "ep number 1392\n",
      "ep number 1393\n",
      "ep number 1394\n",
      "ep number 1395\n",
      "ep number 1396\n",
      "ep number 1397\n",
      "ep number 1398\n",
      "ep number 1399\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1400     |\n",
      "| mean 100 episode reward | -217     |\n",
      "| steps                   | 279799   |\n",
      "--------------------------------------\n",
      "ep number 1400\n",
      "ep number 1401\n",
      "ep number 1402\n",
      "ep number 1403\n",
      "ep number 1404\n",
      "ep number 1405\n",
      "ep number 1406\n",
      "ep number 1407\n",
      "ep number 1408\n",
      "ep number 1409\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1410     |\n",
      "| mean 100 episode reward | -210     |\n",
      "| steps                   | 281799   |\n",
      "--------------------------------------\n",
      "ep number 1410\n",
      "ep number 1411\n",
      "ep number 1412\n",
      "ep number 1413\n",
      "ep number 1414\n",
      "ep number 1415\n",
      "ep number 1416\n",
      "ep number 1417\n",
      "ep number 1418\n",
      "ep number 1419\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1420     |\n",
      "| mean 100 episode reward | -207     |\n",
      "| steps                   | 283799   |\n",
      "--------------------------------------\n",
      "ep number 1420\n",
      "ep number 1421\n",
      "ep number 1422\n",
      "ep number 1423\n",
      "ep number 1424\n",
      "ep number 1425\n",
      "ep number 1426\n",
      "ep number 1427\n",
      "ep number 1428\n",
      "ep number 1429\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1430     |\n",
      "| mean 100 episode reward | -206     |\n",
      "| steps                   | 285799   |\n",
      "--------------------------------------\n",
      "ep number 1430\n",
      "ep number 1431\n",
      "ep number 1432\n",
      "ep number 1433\n",
      "ep number 1434\n",
      "ep number 1435\n",
      "ep number 1436\n",
      "ep number 1437\n",
      "ep number 1438\n",
      "ep number 1439\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1440     |\n",
      "| mean 100 episode reward | -204     |\n",
      "| steps                   | 287799   |\n",
      "--------------------------------------\n",
      "ep number 1440\n",
      "ep number 1441\n",
      "ep number 1442\n",
      "ep number 1443\n",
      "ep number 1444\n",
      "ep number 1445\n",
      "ep number 1446\n",
      "ep number 1447\n",
      "ep number 1448\n",
      "ep number 1449\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1450     |\n",
      "| mean 100 episode reward | -208     |\n",
      "| steps                   | 289799   |\n",
      "--------------------------------------\n",
      "ep number 1450\n",
      "ep number 1451\n",
      "ep number 1452\n",
      "ep number 1453\n",
      "ep number 1454\n",
      "ep number 1455\n",
      "ep number 1456\n",
      "ep number 1457\n",
      "ep number 1458\n",
      "ep number 1459\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1460     |\n",
      "| mean 100 episode reward | -222     |\n",
      "| steps                   | 291799   |\n",
      "--------------------------------------\n",
      "ep number 1460\n",
      "ep number 1461\n",
      "ep number 1462\n",
      "ep number 1463\n",
      "ep number 1464\n",
      "ep number 1465\n",
      "ep number 1466\n",
      "ep number 1467\n",
      "ep number 1468\n",
      "ep number 1469\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1470     |\n",
      "| mean 100 episode reward | -236     |\n",
      "| steps                   | 293799   |\n",
      "--------------------------------------\n",
      "ep number 1470\n",
      "ep number 1471\n",
      "ep number 1472\n",
      "ep number 1473\n",
      "ep number 1474\n",
      "ep number 1475\n",
      "ep number 1476\n",
      "ep number 1477\n",
      "ep number 1478\n",
      "ep number 1479\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1480     |\n",
      "| mean 100 episode reward | -242     |\n",
      "| steps                   | 295799   |\n",
      "--------------------------------------\n",
      "ep number 1480\n",
      "ep number 1481\n",
      "ep number 1482\n",
      "ep number 1483\n",
      "ep number 1484\n",
      "ep number 1485\n",
      "ep number 1486\n",
      "ep number 1487\n",
      "ep number 1488\n",
      "ep number 1489\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1490     |\n",
      "| mean 100 episode reward | -241     |\n",
      "| steps                   | 297799   |\n",
      "--------------------------------------\n",
      "ep number 1490\n",
      "ep number 1491\n",
      "ep number 1492\n",
      "ep number 1493\n",
      "ep number 1494\n",
      "ep number 1495\n",
      "ep number 1496\n",
      "ep number 1497\n",
      "ep number 1498\n",
      "ep number 1499\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1500     |\n",
      "| mean 100 episode reward | -247     |\n",
      "| steps                   | 299799   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep number 1500\n",
      "ep number 1501\n",
      "ep number 1502\n",
      "ep number 1503\n",
      "ep number 1504\n",
      "ep number 1505\n",
      "ep number 1506\n",
      "ep number 1507\n",
      "ep number 1508\n",
      "ep number 1509\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1510     |\n",
      "| mean 100 episode reward | -250     |\n",
      "| steps                   | 301799   |\n",
      "--------------------------------------\n",
      "ep number 1510\n",
      "ep number 1511\n",
      "ep number 1512\n",
      "ep number 1513\n",
      "ep number 1514\n",
      "ep number 1515\n",
      "ep number 1516\n",
      "ep number 1517\n",
      "ep number 1518\n",
      "ep number 1519\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1520     |\n",
      "| mean 100 episode reward | -256     |\n",
      "| steps                   | 303799   |\n",
      "--------------------------------------\n",
      "ep number 1520\n",
      "ep number 1521\n",
      "ep number 1522\n",
      "ep number 1523\n",
      "ep number 1524\n",
      "ep number 1525\n",
      "ep number 1526\n",
      "ep number 1527\n",
      "ep number 1528\n",
      "ep number 1529\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1530     |\n",
      "| mean 100 episode reward | -253     |\n",
      "| steps                   | 305799   |\n",
      "--------------------------------------\n",
      "ep number 1530\n",
      "ep number 1531\n",
      "ep number 1532\n",
      "ep number 1533\n",
      "ep number 1534\n",
      "ep number 1535\n",
      "ep number 1536\n",
      "ep number 1537\n",
      "ep number 1538\n",
      "ep number 1539\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1540     |\n",
      "| mean 100 episode reward | -262     |\n",
      "| steps                   | 307799   |\n",
      "--------------------------------------\n",
      "ep number 1540\n",
      "ep number 1541\n",
      "ep number 1542\n",
      "ep number 1543\n",
      "ep number 1544\n",
      "ep number 1545\n",
      "ep number 1546\n",
      "ep number 1547\n",
      "ep number 1548\n",
      "ep number 1549\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1550     |\n",
      "| mean 100 episode reward | -260     |\n",
      "| steps                   | 309799   |\n",
      "--------------------------------------\n",
      "ep number 1550\n",
      "ep number 1551\n",
      "ep number 1552\n",
      "ep number 1553\n",
      "ep number 1554\n",
      "ep number 1555\n",
      "ep number 1556\n",
      "ep number 1557\n",
      "ep number 1558\n",
      "ep number 1559\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1560     |\n",
      "| mean 100 episode reward | -253     |\n",
      "| steps                   | 311799   |\n",
      "--------------------------------------\n",
      "ep number 1560\n",
      "ep number 1561\n",
      "ep number 1562\n",
      "ep number 1563\n",
      "ep number 1564\n",
      "ep number 1565\n",
      "ep number 1566\n",
      "ep number 1567\n",
      "ep number 1568\n",
      "ep number 1569\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1570     |\n",
      "| mean 100 episode reward | -251     |\n",
      "| steps                   | 313799   |\n",
      "--------------------------------------\n",
      "ep number 1570\n",
      "ep number 1571\n",
      "ep number 1572\n",
      "ep number 1573\n",
      "ep number 1574\n",
      "ep number 1575\n",
      "ep number 1576\n",
      "ep number 1577\n",
      "ep number 1578\n",
      "ep number 1579\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1580     |\n",
      "| mean 100 episode reward | -247     |\n",
      "| steps                   | 315799   |\n",
      "--------------------------------------\n",
      "ep number 1580\n",
      "ep number 1581\n",
      "ep number 1582\n",
      "ep number 1583\n",
      "ep number 1584\n",
      "ep number 1585\n",
      "ep number 1586\n",
      "ep number 1587\n",
      "ep number 1588\n",
      "ep number 1589\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1590     |\n",
      "| mean 100 episode reward | -246     |\n",
      "| steps                   | 317799   |\n",
      "--------------------------------------\n",
      "ep number 1590\n",
      "ep number 1591\n",
      "ep number 1592\n",
      "ep number 1593\n",
      "ep number 1594\n",
      "ep number 1595\n",
      "ep number 1596\n",
      "ep number 1597\n",
      "ep number 1598\n",
      "ep number 1599\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1600     |\n",
      "| mean 100 episode reward | -254     |\n",
      "| steps                   | 319799   |\n",
      "--------------------------------------\n",
      "ep number 1600\n",
      "ep number 1601\n",
      "ep number 1602\n",
      "ep number 1603\n",
      "ep number 1604\n",
      "ep number 1605\n",
      "ep number 1606\n",
      "ep number 1607\n",
      "ep number 1608\n",
      "ep number 1609\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1610     |\n",
      "| mean 100 episode reward | -257     |\n",
      "| steps                   | 321799   |\n",
      "--------------------------------------\n",
      "ep number 1610\n",
      "ep number 1611\n",
      "ep number 1612\n",
      "ep number 1613\n",
      "ep number 1614\n",
      "ep number 1615\n",
      "ep number 1616\n",
      "ep number 1617\n",
      "ep number 1618\n",
      "ep number 1619\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1620     |\n",
      "| mean 100 episode reward | -262     |\n",
      "| steps                   | 323799   |\n",
      "--------------------------------------\n",
      "ep number 1620\n",
      "ep number 1621\n",
      "ep number 1622\n",
      "ep number 1623\n",
      "ep number 1624\n",
      "ep number 1625\n",
      "ep number 1626\n",
      "ep number 1627\n",
      "ep number 1628\n",
      "ep number 1629\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1630     |\n",
      "| mean 100 episode reward | -268     |\n",
      "| steps                   | 325799   |\n",
      "--------------------------------------\n",
      "ep number 1630\n",
      "ep number 1631\n",
      "ep number 1632\n",
      "ep number 1633\n",
      "ep number 1634\n",
      "ep number 1635\n",
      "ep number 1636\n",
      "ep number 1637\n",
      "ep number 1638\n",
      "ep number 1639\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1640     |\n",
      "| mean 100 episode reward | -259     |\n",
      "| steps                   | 327799   |\n",
      "--------------------------------------\n",
      "ep number 1640\n",
      "ep number 1641\n",
      "ep number 1642\n",
      "ep number 1643\n",
      "ep number 1644\n",
      "ep number 1645\n",
      "ep number 1646\n",
      "ep number 1647\n",
      "ep number 1648\n",
      "ep number 1649\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1650     |\n",
      "| mean 100 episode reward | -262     |\n",
      "| steps                   | 329799   |\n",
      "--------------------------------------\n",
      "ep number 1650\n",
      "ep number 1651\n",
      "ep number 1652\n",
      "ep number 1653\n",
      "ep number 1654\n",
      "ep number 1655\n",
      "ep number 1656\n",
      "ep number 1657\n",
      "ep number 1658\n",
      "ep number 1659\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1660     |\n",
      "| mean 100 episode reward | -257     |\n",
      "| steps                   | 331799   |\n",
      "--------------------------------------\n",
      "ep number 1660\n",
      "ep number 1661\n",
      "ep number 1662\n",
      "ep number 1663\n",
      "ep number 1664\n",
      "ep number 1665\n",
      "ep number 1666\n",
      "ep number 1667\n",
      "ep number 1668\n",
      "ep number 1669\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1670     |\n",
      "| mean 100 episode reward | -251     |\n",
      "| steps                   | 333799   |\n",
      "--------------------------------------\n",
      "ep number 1670\n",
      "ep number 1671\n",
      "ep number 1672\n",
      "ep number 1673\n",
      "ep number 1674\n",
      "ep number 1675\n",
      "ep number 1676\n",
      "ep number 1677\n",
      "ep number 1678\n",
      "ep number 1679\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1680     |\n",
      "| mean 100 episode reward | -248     |\n",
      "| steps                   | 335799   |\n",
      "--------------------------------------\n",
      "ep number 1680\n",
      "ep number 1681\n",
      "ep number 1682\n",
      "ep number 1683\n",
      "ep number 1684\n",
      "ep number 1685\n",
      "ep number 1686\n",
      "ep number 1687\n",
      "ep number 1688\n",
      "ep number 1689\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1690     |\n",
      "| mean 100 episode reward | -246     |\n",
      "| steps                   | 337799   |\n",
      "--------------------------------------\n",
      "ep number 1690\n",
      "ep number 1691\n",
      "ep number 1692\n",
      "ep number 1693\n",
      "ep number 1694\n",
      "ep number 1695\n",
      "ep number 1696\n",
      "ep number 1697\n",
      "ep number 1698\n",
      "ep number 1699\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1700     |\n",
      "| mean 100 episode reward | -235     |\n",
      "| steps                   | 339799   |\n",
      "--------------------------------------\n",
      "ep number 1700\n",
      "ep number 1701\n",
      "ep number 1702\n",
      "ep number 1703\n",
      "ep number 1704\n",
      "ep number 1705\n",
      "ep number 1706\n",
      "ep number 1707\n",
      "ep number 1708\n",
      "ep number 1709\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1710     |\n",
      "| mean 100 episode reward | -228     |\n",
      "| steps                   | 341799   |\n",
      "--------------------------------------\n",
      "ep number 1710\n",
      "ep number 1711\n",
      "ep number 1712\n",
      "ep number 1713\n",
      "ep number 1714\n",
      "ep number 1715\n",
      "ep number 1716\n",
      "ep number 1717\n",
      "ep number 1718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep number 1719\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1720     |\n",
      "| mean 100 episode reward | -221     |\n",
      "| steps                   | 343799   |\n",
      "--------------------------------------\n",
      "ep number 1720\n",
      "ep number 1721\n",
      "ep number 1722\n",
      "ep number 1723\n",
      "ep number 1724\n",
      "ep number 1725\n",
      "ep number 1726\n",
      "ep number 1727\n",
      "ep number 1728\n",
      "ep number 1729\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1730     |\n",
      "| mean 100 episode reward | -220     |\n",
      "| steps                   | 345799   |\n",
      "--------------------------------------\n",
      "ep number 1730\n",
      "ep number 1731\n",
      "ep number 1732\n",
      "ep number 1733\n",
      "ep number 1734\n",
      "ep number 1735\n",
      "ep number 1736\n",
      "ep number 1737\n",
      "ep number 1738\n",
      "ep number 1739\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1740     |\n",
      "| mean 100 episode reward | -221     |\n",
      "| steps                   | 347799   |\n",
      "--------------------------------------\n",
      "ep number 1740\n",
      "ep number 1741\n",
      "ep number 1742\n",
      "ep number 1743\n",
      "ep number 1744\n",
      "ep number 1745\n",
      "ep number 1746\n",
      "ep number 1747\n",
      "ep number 1748\n",
      "ep number 1749\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 1750     |\n",
      "| mean 100 episode reward | -219     |\n",
      "| steps                   | 349799   |\n",
      "--------------------------------------\n",
      "ep number 1750\n",
      "ep number 1751\n",
      "ep number 1752\n",
      "ep number 1753\n",
      "ep number 1754\n",
      "ep number 1755\n",
      "ep number 1756\n",
      "ep number 1757\n",
      "ep number 1758\n"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Bdq_mountaincarNew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load('Bdq_mountaincar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "#     print(action)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "#     print(rewards)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(acts)[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sb_action",
   "language": "python",
   "name": "sb_action"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
